# Copyright (c) 2023-2024 Antmicro <www.antmicro.com>
#
# SPDX-License-Identifier: Apache-2.0

config KENNING_INFERENCE_LIB
        bool "kenning_inference_lib Support"
        help
          This option enables the kenning_inference_lib library

config KENNING_MODEL_PATH
        string "path to the model that would be used"
        depends on KENNING_INFERENCE_LIB
        help
          This options selects the model that would be used by backend that
          require model during compilation (i.e. TVM). Can be path or URI to
          Kenning resource (i.e. kenning:///models/classification/magic_wand.h5)

config KENNING_MODEL_COMPILER_ARGS
        string "additional args passed to Kenning model compiler"
        depends on KENNING_INFERENCE_LIB

config KENNING_NRF_UART_SLEEP_AFTER_POLL_WORKAROUND
        bool "workaround for UART reading on NRF"
        depends on KENNING_INFERENCE_LIB
        default 0
        help
          This option adds 1 tick sleep after uart_poll_in. This is a temporary
          solution for UART missing some data when reading.

choice KENNING_COMMUNICATION_PROTOCOL
        prompt "Protocol to be used to communicate with Kenning"
        depends on KENNING_INFERENCE_LIB
        default KENNING_COMMUNICATION_PROTOCOL_UART
        help
          This options selects protocol which will be used to communicate with
          Kenning
          Available options: PROTOCOL_NONE, PROTOCOL_UART

config KENNING_COMMUNICATION_PROTOCOL_NONE
        bool
        prompt "Communication with Kenning disabled"

config KENNING_COMMUNICATION_PROTOCOL_UART
        bool
        prompt "UART protocol"
        select UART_SIFIVE_PORT_1 if UART_SIFIVE

endchoice

config KENNING_RESPONSE_PAYLOAD_SIZE
        int "Size in bytes of the response payload"
        default 1024

config KENNING_MESSAGE_RECV_BUFFER_SIZE
        int "Size in bytes of the buffer used for holding message chunks"
        default 128

choice KENNING_ML_RUNTIME
        prompt "ML runtime to be used"
        depends on KENNING_INFERENCE_LIB
        default KENNING_ML_RUNTIME_STUB
        help
          This option selects ML runtime to be used.
          Available options: KENNING_ML_RUNTIME_STUB, KENNING_ML_RUNTIME_TVM, KENNING_ML_RUNTIME_TFLITE

config KENNING_ML_RUNTIME_STUB
        bool
        prompt "Runtime stub"

config KENNING_ML_RUNTIME_TVM
        bool
        prompt "microTVM runtime"
        select ZEPHYR_TVM_MODULE
        select ZEPHYR_DLPACK_MODULE
        select CMSIS_NN if CPU_CORTEX_M
        select CMSIS_DSP if CPU_CORTEX_M

config KENNING_ML_RUNTIME_TFLITE
        bool
        prompt "TFLite Micro runtime"
        select TENSORFLOW_LITE_MICRO
        select TENSORFLOW_LITE_MICRO_CMSIS_NN_KERNELS if CPU_CORTEX_M
        select CMSIS_NN if CPU_CORTEX_M
        select CMSIS_DSP if CPU_CORTEX_M

config KENNING_ML_RUNTIME_IREE
        bool
        prompt "IREE runtime"
        select ZEPHYR_IREE_MODULE

config KENNING_ML_RUNTIME_LLEXT
        bool
        prompt "Loads Kenning Runtime from Linkable Loadable Extensions."
        select LLEXT

endchoice

choice KENNING_TVM_MODEL
        prompt "TVM model to be loaded"
        default KENNING_TVM_MODEL_GEN if KENNING_MODEL_PATH!=""
        default KENNING_TVM_MODEL_MAGIC_WAND
        depends on KENNING_ML_RUNTIME_TVM || KENNING_ML_RUNTIME_LLEXT
        help
          This option select the ML model to be loaded by TVM runtime.
          Available options: KENNING_TVM_MODEL_MAGIC_WAND, KENNING_TVM_MODE_MAGIC_WAND_INT8, KENNING_TVM_MODEL_GEN

config KENNING_TVM_MODEL_MAGIC_WAND
        bool
        prompt "Magic Wand model"

config KENNING_TVM_MODEL_MAGIC_WAND_INT8
        bool
        prompt "Quantized Magic Wand model"

config KENNING_TVM_MODEL_GEN
        bool
        prompt "Load model from generated source"

endchoice

config KENNING_TVM_HEAP_SIZE
        int "Size in kilobytes of the heap used by TVM"
        default 128
        depends on KENNING_ML_RUNTIME_TVM || KENNING_ML_RUNTIME_LLEXT
        help
          This option sets the size in kilobytes of the heap used by TVM.

config KENNING_TFLITE_BUFFER_SIZE
        int "Size in kilobytes of the buffer for tensor arena and model used by TFLite"
        default 64
        depends on KENNING_ML_RUNTIME_TFLITE
        help
          This option sets the size in bytes of the buffer for tensor arena and model used by TFLite.

choice KENNING_IREE_LOADER
        prompt "loader to be used by IREE"
        depends on KENNING_ML_RUNTIME_IREE
        default KENNING_IREE_LOADER_VMVX
        help
          This option selects the loader to be used by IREE.
          Available options: KENNING_IREE_LOADER_VMVX, KENNING_IREE_LOADER_EMBEDDED_ELF

config KENNING_IREE_LOADER_VMVX
        bool
        prompt "vmvx module loader"

config KENNING_IREE_LOADER_EMBEDDED_ELF
        bool
        prompt "embedded elf loader"

endchoice

module = CALLBACKS
module-str = callbacks
source "subsys/logging/Kconfig.template.log_config"

module = INFERENCE_SERVER
module-str = inference_server
source "subsys/logging/Kconfig.template.log_config"

module = KENNING_PROTOCOL
module-str = kenning_protocol
source "subsys/logging/Kconfig.template.log_config"

module = MODEL
module-str = model
source "subsys/logging/Kconfig.template.log_config"

module = RUNTIME_WRAPPER
module-str = runtime_wrapper
source "subsys/logging/Kconfig.template.log_config"

module = UART
module-str = uart
source "subsys/logging/Kconfig.template.log_config"
